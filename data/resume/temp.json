{
  "originalText": "\n\n姓名：张三\n电话：+86 123-4567-8901 | 邮箱：\nzhangsan@email.com\nGitHub：github.com/zhangsan | 个人博客：zhangsan.blog (可选)\n现居地：北京 | 工作年限：3年\n清华大学 | 计算机科学与技术 硕士\n2020.09 - 2023.06\n• 研究方向：自然语言处理（NLP）、大模型预训练与微调\n• 毕业论文：《基于Transformer的少样本学习在对话系统中的应用》（获优秀论文奖）\n北京大学 | 计算机科学与技术 学士\n2016.09 - 2020.06\nAI研究员（大模型方向） | 字节跳动AILab\n2023.07 - 至今\n• 参与千亿参数大模型的预训练任务，负责数据清洗、分布式训练优化，训练效率提升30%。\n• 设计基于RLHF的对话模型对齐方案，在内部评估中使人工反馈满意度提升25%。\n• 开发模型压缩工具，实现模型推理速度提升2倍（量化+蒸馏技术）。\n大模型微调项目 | 阿里巴巴达摩院（实习）\n教育背景\n工作/项目经历\nMarkdown 转换 PDF 小工具 | markdowntopdf.janqi.comhttps://markdowntopdf.janqi.com/zh.html\n第1页 共3页2025/7/10 15:26\n\n2022.06 - 2022.12\n• 基于LLaMA-2构建垂直领域法律问答模型，通过领域自适应预训练（DAPT）使F1值提升18%。\n• 优化Prompt Engineering流程，减少标注成本40%。\n开源项目 | 个人开发\n• LMFlow-Adaptor：开发支持多模态输入的大模型适配器框架，GitHub Star 500+。\n• Chinese-ChatLLM：开源中文对话微调数据集，被3家创业公司采用。\n• 语言与框架：Python、PyTorch、DeepSpeed、Megatron-LM、vLLM、HuggingFace Transformers\n• 大模型技术：\n◦ 预训练/微调：Full-Parameter/LoRA/P-Tuning/QLoRA\n◦ 推理优化：量化（AWQ/GPTQ）、FlashAttention、张量并行\n◦ 领域应用：Agent设计、RAG、多模态对齐（如LLaVA）\n• 分布式训练：熟练使用FSDP、DDP，有千卡集群调试经验\n• 其他：熟悉LangChain、LlamaIndex等应用开发框架\n• 第一作者，《Efficient Prompt Tuning for Few-shot Learning》, ACL 2023\n• 共同作者专利：《一种大模型推理加速方法》（公开号CNXXXXXX）\n• 对NLP前沿技术（如Mixture of Experts、MoE架构）有持续跟踪\n• 具备扎实的工程能力，能从论文复现到落地部署全流程推进\n• 热衷技术分享，曾在MLNLP社区组织大模型系列讲座\n技术能力\n论文与专利\n自我评价\nMarkdown 转换 PDF 小工具 | markdowntopdf.janqi.comhttps://markdowntopdf.janqi.com/zh.html\n第2页 共3页2025/7/10 15:26\n\nMarkdown 转换 PDF 小工具 | markdowntopdf.janqi.comhttps://markdowntopdf.janqi.com/zh.html\n第3页 共3页2025/7/10 15:26",
  "analysis": {
    "id": "chatcmpl-89DezfCRYveWNdfCQgz81WJMfP2YK",
    "object": "chat.completion",
    "created": 1752143683,
    "model": "gpt-3.5-turbo",
    "choices": [
      {
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "这份简历的信息内容丰富专业"
        },
        "logprobs": null,
        "finish_reason": "stop"
      }
    ],
    "usage": {
      "prompt_tokens": 1115,
      "completion_tokens": 13,
      "total_tokens": 1128,
      "prompt_tokens_details": {
        "text_tokens": 1108,
        "cached_tokens_details": {}
      },
      "completion_tokens_details": {}
    }
  },
  "timestamp": "2025-07-10T10:34:43.895Z"
}